{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5af51a8f-edc3-4ad0-a527-4e52b05af821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a22751ab-a5ae-4e53-8634-6ab9e6ef5556",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.7), please consider upgrading to the latest version (0.3.8).\n",
      "Path to dataset files: C:\\Users\\Dipam1\\.cache\\kagglehub\\datasets\\dmitrybabko\\speech-emotion-recognition-en\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "# Download latest version\n",
    "path_of_dir = kagglehub.dataset_download(\"dmitrybabko/speech-emotion-recognition-en\")\n",
    "\n",
    "print(\"Path to dataset files:\", path_of_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b629724b-de5d-4e80-b480-323591686016",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ravdess_path = path_of_dir + \"/Ravdess/audio_speech_actors_01-24/\"\n",
    "Tess_path = path_of_dir + \"/Tess/\"\n",
    "\n",
    "Ravdess_dir_list = os.listdir(Ravdess_path)\n",
    "Tess_dir_list = os.listdir(Tess_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed08a523-0b42-4642-94eb-bcd2a0030bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f90459ce-319f-4f33-9c33-ebbc948b61f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio(filename=Tess_path + it + '/' + file, autoplay= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "206fb62c-7047-4bb5-8944-de8b0e2c0fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from IPython.display import Audio\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f32f4dae-a1b1-4e61-994f-dfca45e710c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dir = {\n",
    "    \"SAD\": \"sad\",\n",
    "    \"ANG\": \"angry\",\n",
    "    \"DIS\": \"disgust\",\n",
    "    \"FEA\": \"fear\",\n",
    "    \"HAP\": \"happy\",\n",
    "    \"NEU\": \"neutral\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "25d67a73-0e50-487f-bd2f-f5e9d6a872b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "path = []\n",
    "\n",
    "for dirpath, dirnames, filenames  in os.walk('SEM/Crema/'):\n",
    "    for i in range(len(filenames)):\n",
    "        file_path = os.path.join(dirpath,filenames[i])\n",
    "        path.append(file_path)\n",
    "        lab = file_path.split(\"_\")[2]\n",
    "        label.append(map_dir.get(lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5c4cb7b7-7605-4dca-9deb-70ecb4d19f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio(filename=f, autoplay= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c019539e-effb-4372-aff2-666ca2286c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4120  &  4120\n"
     ]
    }
   ],
   "source": [
    "print(len(path), \" & \", len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8e97305e-edf9-427f-ac37-b769014a723a",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dir_savee = {\n",
    "    'a': 'angry',\n",
    "    'd': 'disgust',\n",
    "    'f': 'fear',\n",
    "    'h': 'happy',\n",
    "    'n': 'neutral',\n",
    "    'sa': 'sad',\n",
    "    'su': 'surprise'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6bcaff40-3059-4b22-877a-1ec348044403",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirpath, dirnames, filenames  in os.walk('SEM/Savee/'):\n",
    "    for i in range(len(filenames)):\n",
    "        file_path = os.path.join(dirpath,filenames[i])\n",
    "        path.append(file_path)\n",
    "        # lab = file_path.split(\"_\")[1]\n",
    "        # label.append(map_dir_savee.get(lab.split(\".\")[0][:1]))\n",
    "\n",
    "        part = file_path.split('_')[1]\n",
    "        part = part[:-6]\n",
    "        if part == 'a':\n",
    "            label.append('angry')\n",
    "        elif part == 'd':\n",
    "            label.append('disgust')\n",
    "        elif part == 'f':\n",
    "            label.append('fear')\n",
    "        elif part == 'h':\n",
    "            label.append('happy')\n",
    "        elif part == 'n':\n",
    "            label.append('neutral')\n",
    "        elif part == 'sa':\n",
    "            label.append('sad')\n",
    "        elif part == 'su':\n",
    "            label.append('surprise')\n",
    "        else:\n",
    "            label.append('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "76010772-16cc-4bf6-900e-7fe4d234dce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio(filename=file_path, autoplay= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "45ef8afb-7cbf-455e-8e9d-a759f4389c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4600  &  4600\n"
     ]
    }
   ],
   "source": [
    "print(len(path), \" & \", len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3f92102c-f171-4b76-8ce1-668cf4c052f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in Tess_dir_list:\n",
    "    directories = os.listdir(Tess_path + '/' + it)\n",
    "    for file in directories:\n",
    "        part_emotion = file.split('.')[0]\n",
    "        part_emotion = part_emotion.split('_')[2]\n",
    "        \n",
    "        if part_emotion=='ps':\n",
    "            label.append('surprise')\n",
    "        else:\n",
    "            label.append(part_emotion)\n",
    "        path.append(Tess_path + it + '/' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "812f28a2-1ccd-4896-a47f-4a237d12ae5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7400  &  7400\n"
     ]
    }
   ],
   "source": [
    "print(len(path), \" & \", len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2bb36b37-d1e3-4c06-9f14-f2ce6a62678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ravness_emotion = {\n",
    "    \"1\": \"neutral\", \n",
    "    \"2\": \"calm\", \n",
    "    \"3\": \"happy\", \n",
    "    \"4\": \"sad\", \n",
    "    \"5\": \"angry\", \n",
    "    \"6\": \"fearful\", \n",
    "    \"7\": \"disgust\", \n",
    "    \"8\": \"surprised\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5dbb767a-52e8-4dee-b860-6d1ccf880930",
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in Ravdess_dir_list:\n",
    "    # There are 20 actors  \n",
    "    actor = os.listdir(Ravdess_path + it)\n",
    "    for file in actor:\n",
    "        part = file.split('.')[0]\n",
    "        part = part.split('-')\n",
    "        label.append(ravness_emotion.get(int(part[2])))\n",
    "        path.append(Ravdess_path + it + '/' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "cd751091-9e84-4e34-95ce-9bd814c04731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8840  &  8840\n"
     ]
    }
   ],
   "source": [
    "print(len(path), \" & \", len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf77e12-d8db-435b-ad3c-8b374fbcbf3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "65f69ccd-bd24-4c5b-bc08-67cd423dcfcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SEM/Crema/1001_DFA_ANG_XX.wav',\n",
       " 'SEM/Crema/1001_IEO_ANG_HI.wav',\n",
       " 'SEM/Crema/1001_IEO_HAP_LO.wav',\n",
       " 'SEM/Crema/1001_IOM_DIS_XX.wav',\n",
       " 'SEM/Crema/1001_ITS_DIS_XX.wav']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5f7279d2-f3b0-44d0-b760-73c30c024f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['angry', 'angry', 'happy', 'disgust', 'disgust']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7e69dd58-54f2-4445-b15e-f4ad3eec6bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SEM/Crema/1001_DFA_ANG_XX.wav'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f1abd643-8839-4bdd-bca6-5bb17b78af88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_into_vector(sound):\n",
    "    y, sr = librosa.load(sound, sr=16000)\n",
    "    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    \n",
    "    # plt.figure(figsize=(10, 4))\n",
    "    # librosa.display.specshow(mel_spec_db, sr=sr, x_axis=\"time\", y_axis=\"mel\")\n",
    "    # plt.colorbar()\n",
    "    # plt.show()\n",
    "    return mel_spec_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f5f64adc-3671-4aff-a754-7e84608cc3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_into_vector(\"SEM/Crema/1001_IEO_HAP_LO.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "73e352e8-cceb-425e-b94a-82048ad0f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "# mms.fit_transform(mfccs)\n",
    "# mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9f6524c9-18fa-41de-8685-9ebc48acdedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1f9f8bdb-2d85-4a88-bb78-e99ce2cf2dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"speech\"] = path\n",
    "df[\"label\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "06760ce9-7295-4553-a579-b03358aade52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEM/Crema/1001_DFA_ANG_XX.wav</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEM/Crema/1001_IEO_ANG_HI.wav</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SEM/Crema/1001_IEO_HAP_LO.wav</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SEM/Crema/1001_IOM_DIS_XX.wav</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEM/Crema/1001_ITS_DIS_XX.wav</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          speech    label\n",
       "0  SEM/Crema/1001_DFA_ANG_XX.wav    angry\n",
       "1  SEM/Crema/1001_IEO_ANG_HI.wav    angry\n",
       "2  SEM/Crema/1001_IEO_HAP_LO.wav    happy\n",
       "3  SEM/Crema/1001_IOM_DIS_XX.wav  disgust\n",
       "4  SEM/Crema/1001_ITS_DIS_XX.wav  disgust"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2e89db-0426-4095-9ffc-941578190609",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c38551b-caca-4541-a1cb-521dcb0a6f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8e74e102-9f47-4e4c-8d8e-bc3015f5736e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='label'>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['label'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8745f6b4-a71b-47b3-8ec7-06a45341318e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4423fc-7b9c-4fcd-8b6c-65cd8d325cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503243a9-8c49-4662-86cb-34a4be0cc9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "08913dfa-40a7-4b7d-a9cf-1c8f21133abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(data,random=False,rate=0.035,threshold=0.075):\n",
    "    if random:\n",
    "        rate=np.random.random()*threshold\n",
    "    noise=rate*np.random.uniform()*np.amax(data)\n",
    "    augmented_data=data+noise*np.random.normal(size=data.shape[0])\n",
    "    return augmented_data\n",
    "\n",
    "def shifting(data,rate=1000):\n",
    "    augmented_data=int(np.random.uniform(low=-5,high=5)*rate)\n",
    "    augmented_data=np.roll(data,augmented_data)\n",
    "    return augmented_data\n",
    "\n",
    "def pitching(data,sr,pitch_factor=0.7,random=False):\n",
    "    if random:\n",
    "        pitch_factor=np.random.random() * pitch_factor\n",
    "    return librosa.effects.pitch_shift(y= data,sr= sr,n_steps= pitch_factor)\n",
    "\n",
    "def streching(data,rate=0.8):\n",
    "    return librosa.effects.time_stretch(y =data,rate= rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a60f4e2f-6946-4eb7-9dd8-691c930d5f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zcr(data,frame_length,hop_length):\n",
    "    zcr=librosa.feature.zero_crossing_rate(data,frame_length=frame_length,hop_length=hop_length)\n",
    "    return np.squeeze(zcr)\n",
    "def rmse(data,frame_length=2048,hop_length=512):\n",
    "    rmse=librosa.feature.rms(y=data,frame_length=frame_length,hop_length=hop_length)\n",
    "    return np.squeeze(rmse)\n",
    "def mfcc(data,sr,frame_length=2048,hop_length=512,flatten:bool=True):\n",
    "    mfcc=librosa.feature.mfcc(y=data,sr=sr)\n",
    "    return np.squeeze(mfcc.T)if not flatten else np.ravel(mfcc.T)\n",
    "\n",
    "def extract_features(data,sr,frame_length=2048,hop_length=512):\n",
    "    result=np.array([])\n",
    "    \n",
    "    result=np.hstack((result,\n",
    "                      zcr(data,frame_length,hop_length),\n",
    "                      rmse(data,frame_length,hop_length),\n",
    "                      mfcc(data,sr,frame_length,hop_length)\n",
    "                     ))\n",
    "    return result\n",
    "\n",
    "def get_features(path,duration=2.5, offset=0.6):\n",
    "    data,sr=librosa.load(path,duration=duration,offset=offset)\n",
    "    aud=extract_features(data,sr)\n",
    "    audio=np.array(aud)\n",
    "    \n",
    "    noised_audio=add_noise(data,random=True)\n",
    "    aud2=extract_features(noised_audio,sr)\n",
    "    audio=np.vstack((audio,aud2))\n",
    "    \n",
    "    pitched_audio=pitching(data,sr,random=True)\n",
    "    aud3=extract_features(pitched_audio,sr)\n",
    "    audio=np.vstack((audio,aud3))\n",
    "    \n",
    "    pitched_audio1=pitching(data,sr,random=True)\n",
    "    pitched_noised_audio=add_noise(pitched_audio1,random=True)\n",
    "    aud4=extract_features(pitched_noised_audio,sr)\n",
    "    audio=np.vstack((audio,aud4))\n",
    "    \n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2ec9a914-949e-4f80-ac06-e8dda5ea36ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"label_encoder\"] = df[\"speech\"].apply(get_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e5317d93-8c20-42d0-8f17-4df5240545e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc= StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4b23aa7c-417b-4d5d-895b-41463bdcfab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5920, 128, 128, 1) -- (1480, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, \"--\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeead65d-4273-4df2-9281-e3136cfd2099",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_reshaped = sc.fit_transform(X_train)\n",
    "X_test_reshaped = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e583abc-5bc6-4b99-b4ed-94be2f874cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dabdf7-c7af-4fa5-abec-66db6aeb3119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c77d77-d310-45bf-a653-517e4df1acd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c469fa-885a-45e7-bfd7-bee55c58e595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c891f3-e67d-4680-8cf1-06258b631949",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label_encoder\"] = df[\"speech\"].apply(convert_into_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f446eeab-c421-42f7-ab41-cf591db696be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(10)\n",
    "df[\"speech\"].to_csv(\"Saved_Audio.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d34c5a-0c57-4d80-b763-783b6058196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# le = LabelEncoder()\n",
    "\n",
    "# df[\"label\"] = le.fit_transform(df[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a88682c-a9e4-42c9-856c-f3ed998508f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label_encoder\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce9f3da-bb51-41ab-939b-20a375772034",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea0c133-4fa8-42ae-b666-ac96bd994ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"label\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a7b955-056a-4269-b1aa-6d822ff0fab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce7d4f0-dada-45d4-b79a-7ce8b97c7796",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = df[\"label_encoder\"].apply(lambda x: x.shape)\n",
    "print(shapes.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0131e22d-e37e-4a3b-a452-c8701209e71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "import cv2\n",
    "\n",
    "def resize_array(arr, target_shape=(128, 128)):\n",
    "    # If arr is grayscale (2D), resize and then add channel dimension\n",
    "    resized = cv2.resize(arr, target_shape)\n",
    "    # If you need a channel dimension, expand dims:\n",
    "    if len(resized.shape) == 2:\n",
    "        resized = np.expand_dims(resized, axis=-1)\n",
    "    return resized\n",
    "\n",
    "df[\"label_encoder\"] = df[\"label_encoder\"].apply(lambda x: resize_array(x, target_shape=(128, 128)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0ce8bd4b-51ae-47be-a675-81f5a521b36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8840,)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label_encoder\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d38ff6f3-f971-4910-be65-13362c173458",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[176], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel_encoder\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\shape_base.py:449\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[0;32m    447\u001b[0m shapes \u001b[38;5;241m=\u001b[39m {arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays}\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shapes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall input arrays must have the same shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    451\u001b[0m result_ndim \u001b[38;5;241m=\u001b[39m arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    452\u001b[0m axis \u001b[38;5;241m=\u001b[39m normalize_axis_index(axis, result_ndim)\n",
      "\u001b[1;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "X = np.stack(df[\"label_encoder\"].values)\n",
    "print(X.shape)  # Expected shape: (7400, 128, 128, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12b5634-228b-4a15-b745-786e77ee9b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(-1, 128, 128, 1)  # (samples, height, width, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adafbf7-4ea7-4ff3-b357-1597769ef8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9be176e-2726-40c6-88b1-57c8bfbd5361",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c5d3a9-0309-4618-955b-ac0743aec857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## input split\n",
    "# X = np.expand_dims(X, -1)\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24ab6be-c6e5-4cc4-944e-0d57fd34ea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.reshape((X.shape[0], 1, X.shape[1]))  # Reshaping to (num_samples, 1, 13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22706c05-f53e-4736-9c0f-6c0494b186e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c40378-60fd-48c5-8dd1-faa099b2ea32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9593506-9197-43ac-81d6-20f0612a9a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(enc.categories_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328f3211-4d0e-46e7-ac73-9a2a97f78f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f622ff06-0339-4c5e-9909-70a7ce61697b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "y = enc.fit_transform(df[['label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732362a6-5e7d-45dd-871b-e9762f44c7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe7a199-5d39-4ec9-9d81-fd390b49d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.toarray()\n",
    "y.shape\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db3f190-4dbb-4be9-bf61-0b780acebb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ee47db-eb1f-46c5-901b-f3a761defca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "17e12b24-7e5e-4907-832a-8d0f3f3ffa22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5920, 128, 128, 1) -- (5920, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, \"--\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bf4599-cd2e-4b8f-8aee-7a36422b64bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a02224-8867-4c22-8664-0c1f7d70f690",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(128,128,1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(7, activation='softmax')  # 7 emotion classes\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c083d3e6-556e-4c05-93bb-a55ab8326ff4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=30, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb2aa8a-e861-46bb-b593-e7f61148b610",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = list(range(30))\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, label='train accuracy')\n",
    "plt.plot(epochs, val_acc, label='val accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d436ea-142e-4138-af62-4591b7ae301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584c4ad3-0d60-4bf3-8283-6d1bd1616db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Convert one-hot encoded arrays to class indices\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_test_labels, y_pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b282a94c-db70-4920-8d3b-abd2da6a11d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(confusion_matrix(y_test_labels, y_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d751a5be-7b86-425f-a8a1-cf771b720037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad9cc0c-76da-488c-b247-10965008ddff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba300a6e-8b9f-497b-93e1-be9dbd650955",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_predictions = model.predict(X_test)\n",
    "clf2_predictions = clf2.predict(X_test)\n",
    "combined_predictions = (cnn_predictions + clf2_predictions) / 2.0  # simple averaging\n",
    "final_predictions = np.argmax(combined_predictions, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320501e4-eb1e-4e3d-80e3-8f411099b413",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "audio_file = 'SEM/Savee/JK_d11.wav'\n",
    "mfcc = convert_into_vector(audio_file)  # Ensure it returns 2D (40, T)\n",
    "\n",
    "input_data = resize_array(mfcc, target_shape=(128, 128))\n",
    "\n",
    "# Reshape the feature vector to (batch_size, height, width, channels)\n",
    "input_data = input_data.reshape(-1, 128, 128, 1)\n",
    "\n",
    "# CNN Model Prediction\n",
    "# predictions = model.predict(input_data)\n",
    "# predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "\n",
    "class_labels = {0: \"angry\", 1: \"disgust\", 2: \"fear\", 3: \"happy\", 4: \"neutral\", 5: \"sad\", 6: \"surprise\"}\n",
    "print(\"Predicted emotion:\", class_labels.get(predicted_class, \"Unknown\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c68de3-6f3f-40f8-ab93-140a5a0e3bc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d18a902-bb97-4a20-a2af-2f409b9e05f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('SED-1(67).pkl','wb') as f:\n",
    "#     pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf9f7bf-32f3-42e7-ace8-7b8d0e744a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SED-1(67).pkl', 'rb') as f:\n",
    "    clf2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607d2b96-8cff-410f-a992-78f34b9813ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_clf = clf2.predict(X_test)\n",
    "y_test_labels_ = np.argmax(y_test, axis=1)\n",
    "y_pred_labels_ = np.argmax(y_pred_clf, axis=1)\n",
    "\n",
    "print(classification_report(y_test_labels_, y_pred_labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e92cfe-5f41-4039-9991-250cd981a67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "audio_file = 'SEM/Crema/1075_ITS_HAP_XX.wav'\n",
    "mfcc = convert_into_vector(audio_file)\n",
    "print(\"MFCC shape:\", mfcc.shape)  # Expected output: (60,)\n",
    "\n",
    "# Reshape the feature vector to add batch and channel dimensions (batch_size, timesteps, features)\n",
    "input_data = mfcc.reshape(1, 40, 1)\n",
    "\n",
    "# Predict with your trained model (ensure your model is loaded/trained appropriately)\n",
    "predictions = clf2.predict(input_data)\n",
    "predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "#Map the predicted class index to a human-readable label\n",
    "class_labels = {0: \"angry\", 1: \"disgust\", 2: \"fear\", 3: \"happy\", 4: \"neutral\", 5: \"sad\",6:\"surprise\"}\n",
    "print(\"Predicted emotion:\", class_labels.get(predicted_class, \"Unknown\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
